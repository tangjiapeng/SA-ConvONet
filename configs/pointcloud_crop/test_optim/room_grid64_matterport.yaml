method: conv_onet
data:
  input_type: pointcloud_crop
  classes: ['large_scenes']
  path: #####
  pointcloud_n: 65536 # surface points to encode  
  pointcloud_noise: 0.0  #noise levels
  points_subsample: 65536 # spatial points num  
  points_file: points_iou.npz
  points_iou_file: points_iou.npz
  pointcloud_file: pointcloud.npz
  pointcloud_chamfer_file: pointcloud.npz
  voxels_file: null
  multi_files: null
  unit_size: 0.002 # define the size of a voxel, in meter
  query_vol_size: 25 # query crop in voxel
model:
  local_coord: True
  encoder: pointnet_crop_local_pool
  encoder_kwargs:
    hidden_dim: 32
    plane_type: ['grid']
    unet3d: True
    unet3d_kwargs:
      num_levels: 4 # define the receptive field, 3 -> 32, 4 -> 64
      f_maps: 32
      in_channels: 32
      out_channels: 32
  decoder: simple_local_crop
  decoder_kwargs:
    sample_mode: bilinear # bilinear / nearest
    hidden_size: 32
  c_dim: 32
training:
  out_dir: out/pointcloud_crop/matterport_optim
  batch_size: 2
  model_selection_metric: iou
  model_selection_mode: maximize
  print_every: 100
  visualize_every: 10000
  validate_every: 1000000000 # TODO: validation for crop training
  checkpoint_every: 1000
  backup_every: 10000
  n_workers: 8
  n_workers_val: 4
test:
  threshold: 0.2 #iso-surface
  eval_mesh: true
  eval_pointcloud: false
  model_file: room_grid64.pt #https://s3.eu-central-1.amazonaws.com/avg-projects/convolutional_occupancy_networks/models/pointcloud_crop/room_grid64.pt
generation:
  generation_dir: generation
  vis_n_outputs: 2
  sliding_window: True # generate mesh in the sliding-window manner
  resolution_0: 32  # resolution for each crop, set 128 in ConvONet
  upsampling_steps: 0
test_optim:
  onlyencoder: true
  learning_rate: 0.00003
  decay_rate: 0.3
  n_iter: 2000 # >= 720
  n_step: 800 # >= 300
  batch_size: 3 # 3 ~ 8
  threshold: [0.2, 0.25, 0.3]